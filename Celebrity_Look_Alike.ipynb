{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3-jEOrzloRm"
      },
      "outputs": [],
      "source": [
        "#feature_extractor.py\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "actors = os.listdir('/content/drive/MyDrive/celedata')\n",
        "\n",
        "filenames = []\n",
        "\n",
        "for actor in actors:\n",
        "    for file in os.listdir(os.path.join('/content/drive/MyDrive/celedata',actor)):\n",
        "        filenames.append(os.path.join('/content/drive/MyDrive/celedata',actor,file))\n",
        "\n",
        "pickle.dump(filenames,open('/content/drive/MyDrive/filenames.pkl','wb'))\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.vggface import VGGFace\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "filenames = pickle.load(open('/content/drive/MyDrive/filenames.pkl','rb'))\n",
        "\n",
        "model = VGGFace(model='resnet50',include_top=False,input_shape=(224,224,3),pooling='avg')\n",
        "\n",
        "def feature_extractor(img_path,model):\n",
        "    img = image.load_img(img_path,target_size=(224,224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    expanded_img = np.expand_dims(img_array,axis=0)\n",
        "    preprocessed_img = preprocess_input(expanded_img)\n",
        "\n",
        "    result = model.predict(preprocessed_img).flatten()\n",
        "\n",
        "    return result\n",
        "\n",
        "features = []\n",
        "\n",
        "for file in tqdm(filenames):\n",
        "    features.append(feature_extractor(file,model))\n",
        "\n",
        "pickle.dump(features,open('/content/drive/MyDrive/embedding.pkl','wb'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JZVwg_GnU-7"
      },
      "outputs": [],
      "source": [
        "#streamlit_app.py\n",
        "\n",
        "import streamlit as st \n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.vggface import VGGFace\n",
        "import pickle\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from mtcnn import MTCNN\n",
        "import numpy as np\n",
        "\n",
        "detector = MTCNN()\n",
        "model = VGGFace(model='resnet50',include_top=False,input_shape=(224,224,3),pooling='avg')\n",
        "feature_list = pickle.load(open('/content/drive/MyDrive/embedding.pkl','rb'))\n",
        "filenames = pickle.load(open('/content/drive/MyDrive/filenames.pkl','rb'))\n",
        "\n",
        "def save_uploaded_image(uploaded_image):\n",
        "    try:\n",
        "        with open(os.path.join('uploads',uploaded_image.name),'wb') as f:\n",
        "            f.write(uploaded_image.getbuffer())\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def extract_features(img_path,model,detector):\n",
        "    img = cv2.imread(img_path)\n",
        "    results = detector.detect_faces(img)\n",
        "\n",
        "    x, y, width, height = results[0]['box']\n",
        "\n",
        "    face = img[y:y + height, x:x + width]\n",
        "\n",
        "    #  extract its features\n",
        "    image = Image.fromarray(face)\n",
        "    image = image.resize((224, 224))\n",
        "\n",
        "    face_array = np.asarray(image)\n",
        "\n",
        "    face_array = face_array.astype('float32')\n",
        "\n",
        "    expanded_img = np.expand_dims(face_array, axis=0)\n",
        "    preprocessed_img = preprocess_input(expanded_img)\n",
        "    result = model.predict(preprocessed_img).flatten()\n",
        "    return result\n",
        "\n",
        "def recommend(feature_list,features):\n",
        "    similarity = []\n",
        "    for i in range(len(feature_list)):\n",
        "        similarity.append(cosine_similarity(features.reshape(1, -1), feature_list[i].reshape(1, -1))[0][0])\n",
        "\n",
        "    index_pos = sorted(list(enumerate(similarity)), reverse=True, key=lambda x: x[1])[0][0]\n",
        "    return index_pos\n",
        "\n",
        "st.title('Which bollywood celebrity are you?')\n",
        "\n",
        "uploaded_image = st.file_uploader('Choose an image')\n",
        "\n",
        "if uploaded_image is not None:\n",
        "    # save the image in a directory\n",
        "    if save_uploaded_image(uploaded_image):\n",
        "        # load the image\n",
        "        display_image = Image.open(uploaded_image)\n",
        "\n",
        "        # extract the features\n",
        "        features = extract_features(os.path.join('uploads',uploaded_image.name),model,detector)\n",
        "        # recommend\n",
        "        index_pos = recommend(feature_list,features)\n",
        "        predicted_actor = \" \".join(filenames[index_pos].split('/')[-2].split('_'))\n",
        "        # display\n",
        "        st.header(\"You Look Like: \"+predicted_actor)\n",
        "        col1,col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.image(display_image,width=250)\n",
        "            st.header(\"Your Image\")\n",
        "        with col2:\n",
        "            st.image(filenames[index_pos],width=250)\n",
        "            st.header(\"Predicted Celebrity\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLN67TgsonO4",
        "outputId": "13d1b990-472e-4db4-e85b-412b1550ed62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[############......] - finalize:yargs: sill finalize /root/.npm/_npx/1449/lib/n\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.606s\n",
            "your url is: https://pink-shrimps-cheat-104-154-241-46.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.154.241.46:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2022-11-28 06:03:08.894774: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "1/1 [==============================] - 0s 401ms/step\n",
            "1/1 [==============================] - 0s 216ms/step\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "10/10 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 169ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 208ms/step\n",
            "2022-11-28 06:15:21.564 5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe961504950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 156ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 175ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "2022-11-28 06:16:37.328 5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe9615c93b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 227ms/step\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 151ms/step\n",
            "1/1 [==============================] - 0s 174ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 193ms/step\n",
            "1/1 [==============================] - 0s 153ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 185ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ],
      "source": [
        "!streamlit run /content/streamlit_app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}